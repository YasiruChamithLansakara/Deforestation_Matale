{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7094cbf3",
   "metadata": {},
   "source": [
    "## Deforestation Prediction Models - Matale District\n",
    "\n",
    "Advanced machine learning models for forecasting deforestation trends using cloud-masked Landsat data.\n",
    "\n",
    "### üéØ **Models Implemented**\n",
    "1. **Random Forest Regression** - Ensemble learning with temporal features\n",
    "2. **Random Forest Pixel-Level** - Spatial feature analysis (simulated)\n",
    "3. **XGBoost Regression** - Gradient boosting for improved accuracy\n",
    "4. **SARIMA** - Seasonal Autoregressive Integrated Moving Average\n",
    "\n",
    "### üìä **Analysis Pipeline**\n",
    "- Data loading & cloud coverage integration\n",
    "- Quality filtering (>50% cloud removal)\n",
    "- Feature engineering (temporal + spatial)\n",
    "- Model training & evaluation\n",
    "- Comparative performance analysis\n",
    "- Long-term forecasting (2026-2030)\n",
    "\n",
    "### üîë **Key Features**\n",
    "- Cloud-masked data for accurate baseline\n",
    "- Multi-model ensemble approach\n",
    "- Temporal and spatial feature extraction\n",
    "- Comprehensive performance metrics (MAE, RMSE, R¬≤)\n",
    "- Future projections with cumulative impact analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27ad356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEFORESTATION PREDICTION MODELS - MATALE DISTRICT\n",
      "Multi-Model Comparison: RF, RF-Pixel, XGBoost, SARIMA\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "2. DATA LOADING & CLOUD COVERAGE INTEGRATION\n",
      "======================================================================\n",
      "‚úì Loaded monthly dataset: 218 rows\n",
      "  Date range: 2013-05-26 ‚Üí 2024-12-26\n",
      "‚úì Cloud coverage integrated\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Series.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     58\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ö† Cloud coverage file not found (older data format)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m df = \u001b[43mload_deforestation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# 3. DATA PREPROCESSING & QUALITY FILTERING\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mload_deforestation_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     54\u001b[39m         avg_cloud = df[\u001b[33m'\u001b[39m\u001b[33mCloud_Coverage\u001b[39m\u001b[33m'\u001b[39m].mean()\n\u001b[32m     55\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úì Cloud coverage integrated\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Average cloud coverage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_cloud\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ö† Cloud coverage file not found (older data format)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported format string passed to Series.__format__"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEFORESTATION PREDICTION MODELS - MATALE DISTRICT\")\n",
    "print(\"Multi-Model Comparison: RF, RF-Pixel, XGBoost, SARIMA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# 1. CONFIGURATION & SETUP\n",
    "# ============================================================\n",
    "BASE_DIR = r\"D:\\Satellite Image Processing\\Deforestation_Matale\"\n",
    "MONTHLY_FILE = os.path.join(BASE_DIR, \"Processed_Monthly\", \"Monthly_Deforestation_Stats.csv\")\n",
    "CLOUD_FILE = os.path.join(BASE_DIR, \"Processed_Monthly\", \"Cloud_Coverage_Stats.csv\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"Model_Comparison\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# 2. DATA LOADING & CLOUD COVERAGE INTEGRATION\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. DATA LOADING & CLOUD COVERAGE INTEGRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def load_deforestation_data():\n",
    "    \"\"\"Load deforestation data with cloud coverage metrics\"\"\"\n",
    "    if not os.path.exists(MONTHLY_FILE):\n",
    "        raise FileNotFoundError(f\"Data file not found: {MONTHLY_FILE}\")\n",
    "\n",
    "    df = pd.read_csv(MONTHLY_FILE, parse_dates=[\"Date\"]).sort_values(\"Date\")\n",
    "    print(f\"‚úì Loaded monthly dataset: {len(df)} rows\")\n",
    "    print(f\"  Date range: {df['Date'].min().date()} ‚Üí {df['Date'].max().date()}\")\n",
    "\n",
    "    # Load cloud coverage if available\n",
    "    if os.path.exists(CLOUD_FILE):\n",
    "        cloud_df = pd.read_csv(CLOUD_FILE, parse_dates=[\"date\"]).rename(columns={\"date\": \"Date\"})\n",
    "        df = df.merge(cloud_df[[\"Date\", \"cloud_coverage\"]], on=\"Date\", how=\"left\")\n",
    "        df.rename(columns={\"cloud_coverage\": \"Cloud_Coverage\"}, inplace=True)\n",
    "\n",
    "        if \"Cloud_Coverage\" in df.columns:\n",
    "            avg_cloud = df['Cloud_Coverage'].mean()\n",
    "            print(f\"‚úì Cloud coverage integrated\")\n",
    "            print(f\"  Average cloud coverage: {avg_cloud:.1f}%\")\n",
    "    else:\n",
    "        print(\"‚ö† Cloud coverage file not found (older data format)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = load_deforestation_data()\n",
    "\n",
    "# ============================================================\n",
    "# 3. DATA PREPROCESSING & QUALITY FILTERING\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. DATA PREPROCESSING & QUALITY FILTERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Remove high cloud coverage scenes\n",
    "original_len = len(df)\n",
    "if \"Cloud_Coverage\" in df.columns:\n",
    "    df = df[df[\"Cloud_Coverage\"] <= 50].copy()\n",
    "    removed = original_len - len(df)\n",
    "    if removed > 0:\n",
    "        print(f\"‚úì Removed {removed} scenes with >50% cloud coverage\")\n",
    "\n",
    "# Handle missing values\n",
    "if df[\"Deforested_Area_km2\"].isna().any():\n",
    "    missing_count = df[\"Deforested_Area_km2\"].isna().sum()\n",
    "    df[\"Deforested_Area_km2\"].interpolate(method='linear', inplace=True)\n",
    "    print(f\"‚úì Interpolated {missing_count} missing deforestation values\")\n",
    "\n",
    "print(f\"‚úì Final dataset size: {len(df)} scenes\")\n",
    "\n",
    "# Train/Test split\n",
    "train_size = int(len(df) * 0.85)\n",
    "train_df = df.iloc[:train_size]\n",
    "test_df = df.iloc[train_size:]\n",
    "\n",
    "y_train, y_test = train_df[\"Deforested_Area_km2\"], test_df[\"Deforested_Area_km2\"]\n",
    "X_train_index, X_test_index = train_df[\"Date\"], test_df[\"Date\"]\n",
    "\n",
    "print(f\"‚úì Train/Test split: {len(train_df)} / {len(test_df)} scenes\")\n",
    "print(f\"  Training period: {train_df['Date'].min().date()} ‚Üí {train_df['Date'].max().date()}\")\n",
    "print(f\"  Testing period: {test_df['Date'].min().date()} ‚Üí {test_df['Date'].max().date()}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Temporal features\n",
    "df[\"Month\"] = df[\"Date\"].dt.month\n",
    "df[\"Year\"] = df[\"Date\"].dt.year\n",
    "df[\"Quarter\"] = df[\"Date\"].dt.quarter\n",
    "df[\"DayOfYear\"] = df[\"Date\"].dt.dayofyear\n",
    "\n",
    "# Base feature set\n",
    "feature_cols = [\"Month\", \"Year\", \"Quarter\"]\n",
    "\n",
    "# Add cloud coverage if available\n",
    "if \"Cloud_Coverage\" in df.columns:\n",
    "    feature_cols.append(\"Cloud_Coverage\")\n",
    "    print(\"‚úì Added cloud coverage as feature\")\n",
    "\n",
    "# Add valid pixels if available\n",
    "if \"Valid_Pixels\" in df.columns:\n",
    "    feature_cols.append(\"Valid_Pixels\")\n",
    "    print(\"‚úì Added valid pixel count as feature\")\n",
    "\n",
    "print(f\"‚úì Feature set: {feature_cols}\")\n",
    "\n",
    "# Prepare feature matrices\n",
    "X = df[feature_cols]\n",
    "y = df[\"Deforested_Area_km2\"]\n",
    "\n",
    "X_train = X.iloc[:train_size]\n",
    "X_test = X.iloc[train_size:]\n",
    "y_train_ml = y.iloc[:train_size]\n",
    "y_test_ml = y.iloc[train_size:]\n",
    "\n",
    "# Simulated pixel-level features (placeholder for future spatial analysis)\n",
    "print(\"\\n‚úì Generating simulated pixel-level features...\")\n",
    "np.random.seed(42)\n",
    "df[\"Pixel_Mean\"] = np.random.uniform(0, 1, len(df))\n",
    "df[\"Pixel_Variance\"] = np.random.uniform(0, 0.3, len(df))\n",
    "df[\"Pixel_Texture\"] = np.random.uniform(0, 0.1, len(df))\n",
    "\n",
    "px_cols = [\"Pixel_Mean\", \"Pixel_Variance\", \"Pixel_Texture\"]\n",
    "\n",
    "X_px = df[px_cols]\n",
    "X_px_train = X_px.iloc[:train_size]\n",
    "X_px_test = X_px.iloc[train_size:]\n",
    "\n",
    "# ============================================================\n",
    "# 5. MODEL TRAINING & EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5.1 Random Forest Regression\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5.1 RANDOM FOREST REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, max_depth=12, random_state=42)\n",
    "rf.fit(X_train, y_train_ml)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "rf_mae = mean_absolute_error(y_test_ml, rf_pred)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test_ml, rf_pred))\n",
    "rf_r2 = r2_score(y_test_ml, rf_pred)\n",
    "\n",
    "print(f\"‚úì Random Forest Performance:\")\n",
    "print(f\"  MAE:  {rf_mae:.3f} km¬≤\")\n",
    "print(f\"  RMSE: {rf_rmse:.3f} km¬≤\")\n",
    "print(f\"  R¬≤:   {rf_r2:.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(f\"\\n  Feature Importance:\")\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"    {row['Feature']}: {row['Importance']:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5.2 Random Forest Pixel-Level Model (Simulated)\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5.2 RANDOM FOREST - PIXEL LEVEL (Simulated)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Note: Using simulated pixel features as placeholder\")\n",
    "\n",
    "rf_px = RandomForestRegressor(n_estimators=300, max_depth=10, random_state=42)\n",
    "rf_px.fit(X_px_train, y_train_ml)\n",
    "rf_px_pred = rf_px.predict(X_px_test)\n",
    "\n",
    "rfpx_mae = mean_absolute_error(y_test_ml, rf_px_pred)\n",
    "rfpx_rmse = np.sqrt(mean_squared_error(y_test_ml, rf_px_pred))\n",
    "rfpx_r2 = r2_score(y_test_ml, rf_px_pred)\n",
    "\n",
    "print(f\"‚úì RF Pixel-Level Performance:\")\n",
    "print(f\"  MAE:  {rfpx_mae:.3f} km¬≤\")\n",
    "print(f\"  RMSE: {rfpx_rmse:.3f} km¬≤\")\n",
    "print(f\"  R¬≤:   {rfpx_r2:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5.3 XGBoost Regression\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5.3 XGBOOST REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=300, \n",
    "    learning_rate=0.05, \n",
    "    max_depth=6,\n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8, \n",
    "    random_state=42\n",
    ")\n",
    "xgb.fit(X_train, y_train_ml)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "xgb_mae = mean_absolute_error(y_test_ml, xgb_pred)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test_ml, xgb_pred))\n",
    "xgb_r2 = r2_score(y_test_ml, xgb_pred)\n",
    "\n",
    "print(f\"‚úì XGBoost Performance:\")\n",
    "print(f\"  MAE:  {xgb_mae:.3f} km¬≤\")\n",
    "print(f\"  RMSE: {xgb_rmse:.3f} km¬≤\")\n",
    "print(f\"  R¬≤:   {xgb_r2:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5.4 SARIMA Model\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5.4 SARIMA (Seasonal ARIMA)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    sarima_model = SARIMAX(\n",
    "        y_train, \n",
    "        order=(1,1,1), \n",
    "        seasonal_order=(1,1,1,12),\n",
    "        enforce_stationarity=False, \n",
    "        enforce_invertibility=False\n",
    "    ).fit(disp=False)\n",
    "\n",
    "    sarima_pred = sarima_model.forecast(len(y_test))\n",
    "\n",
    "    sarima_mae = mean_absolute_error(y_test, sarima_pred)\n",
    "    sarima_rmse = np.sqrt(mean_squared_error(y_test, sarima_pred))\n",
    "    sarima_r2 = r2_score(y_test, sarima_pred)\n",
    "\n",
    "    print(f\"‚úì SARIMA Performance:\")\n",
    "    print(f\"  MAE:  {sarima_mae:.3f} km¬≤\")\n",
    "    print(f\"  RMSE: {sarima_rmse:.3f} km¬≤\")\n",
    "    print(f\"  R¬≤:   {sarima_r2:.3f}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† SARIMA model failed: {str(e)}\")\n",
    "    # Fallback predictions\n",
    "    sarima_pred = np.full(len(y_test), y_train.mean())\n",
    "    sarima_mae = mean_absolute_error(y_test, sarima_pred)\n",
    "    sarima_rmse = np.sqrt(mean_squared_error(y_test, sarima_pred))\n",
    "    sarima_r2 = r2_score(y_test, sarima_pred)\n",
    "    print(f\"‚úì Using fallback (mean) predictions\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. MODEL COMPARISON & RESULTS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6. MODEL COMPARISON & RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Random Forest\", \"RF Pixel-Level\", \"XGBoost\", \"SARIMA\"],\n",
    "    \"MAE (km¬≤)\": [rf_mae, rfpx_mae, xgb_mae, sarima_mae],\n",
    "    \"RMSE (km¬≤)\": [rf_rmse, rfpx_rmse, xgb_rmse, sarima_rmse],\n",
    "    \"R¬≤\": [rf_r2, rfpx_r2, xgb_r2, sarima_r2]\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Performance Comparison:\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "results.to_csv(os.path.join(OUTPUT_DIR, \"Model_Comparison_Results.csv\"), index=False)\n",
    "print(f\"\\n‚úì Results saved to: Model_Comparison_Results.csv\")\n",
    "\n",
    "# Identify best model\n",
    "best_idx = results[\"RMSE (km¬≤)\"].idxmin()\n",
    "best_model = results.loc[best_idx, \"Model\"]\n",
    "best_rmse = results.loc[best_idx, \"RMSE (km¬≤)\"]\n",
    "\n",
    "print(f\"\\nüèÜ Best Performing Model: {best_model}\")\n",
    "print(f\"   RMSE: {best_rmse:.3f} km¬≤\")\n",
    "\n",
    "# Store best model object for later use\n",
    "if best_model == \"Random Forest\":\n",
    "    final_model = rf\n",
    "    model_type = \"RF\"\n",
    "elif best_model == \"RF Pixel-Level\":\n",
    "    final_model = rf_px\n",
    "    model_type = \"RF-Pixel\"\n",
    "elif best_model == \"XGBoost\":\n",
    "    final_model = xgb\n",
    "    model_type = \"XGBoost\"\n",
    "else:\n",
    "    final_model = sarima_model\n",
    "    model_type = \"SARIMA\"\n",
    "\n",
    "# ============================================================\n",
    "# 7. VISUALIZATION - FORECAST COMPARISON\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"7. VISUALIZATION - FORECAST COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12), sharex=True)\n",
    "\n",
    "# Plot 1: Model predictions\n",
    "axes[0].plot(df[\"Date\"], df[\"Deforested_Area_km2\"], \n",
    "            label=\"Observed\", color=\"black\", linewidth=2.5, marker='o', markersize=3)\n",
    "axes[0].plot(X_test_index, rf_pred, \"--\", label=\"Random Forest\", \n",
    "            linewidth=2, marker='s', markersize=4)\n",
    "axes[0].plot(X_test_index, rf_px_pred, \"--\", label=\"RF Pixel-Level\", \n",
    "            linewidth=2, marker='^', markersize=4)\n",
    "axes[0].plot(X_test_index, xgb_pred, \"--\", label=\"XGBoost\", \n",
    "            linewidth=2, marker='d', markersize=4)\n",
    "axes[0].plot(X_test_index, sarima_pred, \"--\", label=\"SARIMA\", \n",
    "            linewidth=2, marker='x', markersize=4)\n",
    "axes[0].axvline(x=train_df['Date'].max(), color='orange', linestyle=':', \n",
    "               linewidth=2, alpha=0.7, label='Train/Test Split')\n",
    "axes[0].set_title(\"Model Forecast Comparison - Matale District\\n(Based on Cloud-Masked Data)\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel(\"Deforested Area (km¬≤)\", fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cloud coverage\n",
    "if 'Cloud_Coverage' in df.columns:\n",
    "    axes[1].bar(df[\"Date\"], df[\"Cloud_Coverage\"], color='lightblue', alpha=0.6, label='Cloud Coverage')\n",
    "    axes[1].axhline(y=50, color='red', linestyle='--', linewidth=2, alpha=0.5, label='50% Threshold')\n",
    "    axes[1].set_title(\"Cloud Coverage per Scene\", fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel(\"Cloud Coverage (%)\", fontsize=12)\n",
    "else:\n",
    "    # Show residuals if no cloud data\n",
    "    axes[1].plot(X_test_index, y_test.values - rf_pred, 'o-', label='RF Residuals', alpha=0.7)\n",
    "    axes[1].plot(X_test_index, y_test.values - xgb_pred, 's-', label='XGBoost Residuals', alpha=0.7)\n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[1].set_title(\"Model Prediction Residuals\", fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel(\"Residual (km¬≤)\", fontsize=12)\n",
    "\n",
    "axes[1].set_xlabel(\"Date\", fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"Model_Forecast_Comparison.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization saved to: Model_Forecast_Comparison.png\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. K-MEANS CLUSTERING ANALYSIS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"8. K-MEANS CLUSTERING ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Clustering features\n",
    "cluster_features = [\"Deforested_Area_km2\"]\n",
    "if 'Cloud_Coverage' in df.columns:\n",
    "    cluster_features.append(\"Cloud_Coverage\")\n",
    "\n",
    "X_cluster = StandardScaler().fit_transform(df[cluster_features])\n",
    "kmeans = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
    "df[\"Cluster\"] = kmeans.fit_predict(X_cluster)\n",
    "\n",
    "# Cluster statistics\n",
    "cluster_stats = df.groupby('Cluster')['Deforested_Area_km2'].agg(['mean', 'min', 'max', 'count'])\n",
    "print(\"\\n‚úì Cluster Statistics (Deforestation):\")\n",
    "print(cluster_stats)\n",
    "\n",
    "if 'Cloud_Coverage' in df.columns:\n",
    "    cloud_cluster_stats = df.groupby('Cluster')['Cloud_Coverage'].agg(['mean', 'min', 'max'])\n",
    "    print(\"\\n‚úì Cluster Statistics (Cloud Coverage):\")\n",
    "    print(cloud_cluster_stats)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.scatterplot(x=\"Date\", y=\"Deforested_Area_km2\", hue=\"Cluster\", \n",
    "               palette=\"Set2\", data=df, s=60)\n",
    "plt.title(\"Temporal Clustering of Deforestation Patterns (K=3)\\nBased on Cloud-Masked Data\", \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Deforested Area (km¬≤)\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"KMeans_Temporal_Clusters.png\"), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Save clustered data\n",
    "df.to_csv(os.path.join(OUTPUT_DIR, \"Deforestation_with_Clusters.csv\"), index=False)\n",
    "print(\"\\n‚úì Clustered data saved to: Deforestation_with_Clusters.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ MODEL TRAINING & COMPARISON COMPLETE!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecf551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 9. LONG-TERM FORECASTING (2026-2030)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"9. LONG-TERM FORECASTING (2026-2030)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Using best model: {best_model} ({model_type})\")\n",
    "\n",
    "# ============================================================\n",
    "# 9.1 Generate Future Dates\n",
    "# ============================================================\n",
    "last_date = df[\"Date\"].max()\n",
    "future_dates = pd.date_range(start=last_date + pd.offsets.MonthBegin(1),\n",
    "                             end=\"2030-12-31\", freq=\"MS\")\n",
    "\n",
    "future_df = pd.DataFrame({\"Date\": future_dates})\n",
    "\n",
    "# Add temporal features\n",
    "future_df[\"Month\"] = future_df[\"Date\"].dt.month\n",
    "future_df[\"Year\"] = future_df[\"Date\"].dt.year\n",
    "future_df[\"Quarter\"] = future_df[\"Date\"].dt.quarter\n",
    "\n",
    "# Cloud coverage assumption: use training average for future\n",
    "if \"Cloud_Coverage\" in df.columns and \"Cloud_Coverage\" in feature_cols:\n",
    "    avg_cloud = df[\"Cloud_Coverage\"].mean()\n",
    "    future_df[\"Cloud_Coverage\"] = avg_cloud\n",
    "    print(f\"‚úì Using average cloud coverage for future: {avg_cloud:.1f}%\")\n",
    "\n",
    "# Valid pixels: use training average if available\n",
    "if \"Valid_Pixels\" in df.columns and \"Valid_Pixels\" in feature_cols:\n",
    "    avg_valid_pixels = df[\"Valid_Pixels\"].mean()\n",
    "    future_df[\"Valid_Pixels\"] = avg_valid_pixels\n",
    "    print(f\"‚úì Using average valid pixels: {avg_valid_pixels:,.0f}\")\n",
    "\n",
    "print(f\"‚úì Generated {len(future_df)} monthly predictions\")\n",
    "\n",
    "# ============================================================\n",
    "# 9.2 Make Predictions Based on Best Model\n",
    "# ============================================================\n",
    "if model_type in [\"RF\", \"XGBoost\"]:\n",
    "    # Tree-based models use temporal features\n",
    "    future_preds = final_model.predict(future_df[feature_cols])\n",
    "\n",
    "elif model_type == \"RF-Pixel\":\n",
    "    # Pixel-level model: use average pixel features\n",
    "    future_df[\"Pixel_Mean\"] = df[\"Pixel_Mean\"].mean()\n",
    "    future_df[\"Pixel_Variance\"] = df[\"Pixel_Variance\"].mean()\n",
    "    future_df[\"Pixel_Texture\"] = df[\"Pixel_Texture\"].mean()\n",
    "    future_preds = final_model.predict(future_df[px_cols])\n",
    "\n",
    "elif model_type == \"SARIMA\":\n",
    "    # Time series model: direct forecast\n",
    "    steps = len(future_df)\n",
    "    future_preds = final_model.forecast(steps=steps)\n",
    "\n",
    "future_df[\"Predicted_Deforested_Area_km2\"] = future_preds\n",
    "\n",
    "# ============================================================\n",
    "# 9.3 Calculate Yearly Projections\n",
    "# ============================================================\n",
    "print(\"\\nüìä Calculating yearly projections...\")\n",
    "\n",
    "yearly_forecast = future_df.groupby(\"Year\")[\"Predicted_Deforested_Area_km2\"].mean().reset_index()\n",
    "yearly_forecast.columns = [\"Year\", \"Projected_Area_km2\"]\n",
    "\n",
    "# Current baseline\n",
    "baseline = df[\"Deforested_Area_km2\"].iloc[-1]\n",
    "current_year = df[\"Date\"].iloc[-1].year\n",
    "\n",
    "print(f\"\\n‚úì Baseline ({current_year}): {baseline:.2f} km¬≤\")\n",
    "\n",
    "# Calculate cumulative increase from baseline\n",
    "cumulative_results = []\n",
    "\n",
    "for _, row in yearly_forecast.iterrows():\n",
    "    year = int(row[\"Year\"])\n",
    "    projected = row[\"Projected_Area_km2\"]\n",
    "    increase = projected - baseline\n",
    "    increase_pct = (increase / baseline) * 100 if baseline > 0 else 0\n",
    "\n",
    "    cumulative_results.append({\n",
    "        \"Year\": year,\n",
    "        \"Projected_Area_km2\": projected,\n",
    "        \"Cumulative_Increase_km2\": increase,\n",
    "        \"Cumulative_Increase_Pct\": increase_pct\n",
    "    })\n",
    "\n",
    "cumulative_df = pd.DataFrame(cumulative_results)\n",
    "\n",
    "# ============================================================\n",
    "# 9.4 Display & Save Results\n",
    "# ============================================================\n",
    "print(\"\\nüìà Yearly Deforestation Projections:\")\n",
    "print(\"=\"*70)\n",
    "print(cumulative_df.to_string(index=False))\n",
    "\n",
    "# Highlight 2030 projection\n",
    "projection_2030 = cumulative_df[cumulative_df[\"Year\"] == 2030]\n",
    "if len(projection_2030) > 0:\n",
    "    final_2030 = projection_2030.iloc[0]\n",
    "    print(f\"\\nüéØ 2030 PROJECTION:\")\n",
    "    print(f\"   Projected deforested area: {final_2030['Projected_Area_km2']:.2f} km¬≤\")\n",
    "    print(f\"   Increase from current: {final_2030['Cumulative_Increase_km2']:.2f} km¬≤ ({final_2030['Cumulative_Increase_Pct']:+.1f}%)\")\n",
    "\n",
    "# Save results\n",
    "yearly_path = os.path.join(OUTPUT_DIR, \"Yearly_Projections_2030.csv\")\n",
    "cumulative_df.to_csv(yearly_path, index=False)\n",
    "print(f\"\\n‚úì Yearly projections saved to: Yearly_Projections_2030.csv\")\n",
    "\n",
    "# Save full monthly forecast\n",
    "monthly_path = os.path.join(OUTPUT_DIR, \"Monthly_Forecast_2030.csv\")\n",
    "future_df.to_csv(monthly_path, index=False)\n",
    "print(f\"‚úì Monthly forecast saved to: Monthly_Forecast_2030.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# 9.5 Visualization - Long-Term Forecast\n",
    "# ============================================================\n",
    "print(\"\\nüìä Generating long-term forecast visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12), sharex=True)\n",
    "\n",
    "# Plot 1: Historical + Forecast\n",
    "axes[0].plot(df[\"Date\"], df[\"Deforested_Area_km2\"], \n",
    "            label=\"Historical Deforestation (Cloud-Masked)\", \n",
    "            color=\"darkgreen\", linewidth=3, marker='o', markersize=4)\n",
    "\n",
    "axes[0].plot(future_df[\"Date\"], future_df[\"Predicted_Deforested_Area_km2\"], \n",
    "            label=f\"{best_model} Long-term Forecast\", \n",
    "            color=\"red\", linewidth=2.5, linestyle='--', marker='s', markersize=3)\n",
    "\n",
    "# Mark forecast start\n",
    "axes[0].axvline(x=df[\"Date\"].max(), color=\"orange\", linestyle=\":\", \n",
    "               linewidth=2.5, alpha=0.8, label=\"Forecast Start\")\n",
    "\n",
    "# Mark 2030\n",
    "axes[0].axvline(x=pd.to_datetime(\"2030-12-31\"), color=\"purple\", \n",
    "               linestyle=\":\", linewidth=2, alpha=0.6, label=\"2030 Target\")\n",
    "\n",
    "axes[0].set_title(f\"Long-Term Deforestation Forecast - Matale District (2026-2030)\\nModel: {best_model}\", \n",
    "                 fontsize=16, fontweight='bold')\n",
    "axes[0].set_ylabel(\"Deforested Area (km¬≤)\", fontsize=13)\n",
    "axes[0].legend(fontsize=11, loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Plot 2: Yearly projections as bar chart\n",
    "axes[1].bar(cumulative_df[\"Year\"], cumulative_df[\"Projected_Area_km2\"], \n",
    "           color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[1].axhline(y=baseline, color='red', linestyle='--', \n",
    "               linewidth=2, alpha=0.7, label=f'Current Level ({baseline:.1f} km¬≤)')\n",
    "axes[1].set_title(\"Yearly Average Deforestation Projection\", fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel(\"Year\", fontsize=13)\n",
    "axes[1].set_ylabel(\"Projected Area (km¬≤)\", fontsize=13)\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"Long_Term_Forecast_2030.png\"), dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization saved to: Long_Term_Forecast_2030.png\")\n",
    "\n",
    "# ============================================================\n",
    "# 10. SUMMARY & RECOMMENDATIONS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"10. SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìÅ All results saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "print(\"\\nüì¶ Generated Files:\")\n",
    "print(\"  ‚Ä¢ Model_Comparison_Results.csv - Performance metrics\")\n",
    "print(\"  ‚Ä¢ Model_Forecast_Comparison.png - Visual comparison\")\n",
    "print(\"  ‚Ä¢ KMeans_Temporal_Clusters.png - Clustering analysis\")\n",
    "print(\"  ‚Ä¢ Deforestation_with_Clusters.csv - Data with clusters\")\n",
    "print(\"  ‚Ä¢ Yearly_Projections_2030.csv - Yearly forecasts\")\n",
    "print(\"  ‚Ä¢ Monthly_Forecast_2030.csv - Monthly predictions\")\n",
    "print(\"  ‚Ä¢ Long_Term_Forecast_2030.png - Long-term visualization\")\n",
    "\n",
    "print(\"\\nüå≤ Conservation Applications:\")\n",
    "print(\"  ‚Ä¢ Plan forest conservation interventions\")\n",
    "print(\"  ‚Ä¢ Identify high-risk deforestation zones\")\n",
    "print(\"  ‚Ä¢ Set realistic reforestation targets\")\n",
    "print(\"  ‚Ä¢ Monitor progress against projected trends\")\n",
    "print(\"  ‚Ä¢ Allocate conservation resources effectively\")\n",
    "\n",
    "if 'Cloud_Coverage' in df.columns:\n",
    "    print(\"\\n‚õÖ Cloud Masking Impact:\")\n",
    "    print(f\"  ‚Ä¢ Historical data filtered for <50% cloud coverage\")\n",
    "    print(f\"  ‚Ä¢ Average cloud coverage: {df['Cloud_Coverage'].mean():.1f}%\")\n",
    "    print(f\"  ‚Ä¢ Future predictions assume stable cloud patterns\")\n",
    "    print(f\"  ‚Ä¢ Improved baseline accuracy through quality filtering\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Important Considerations:\")\n",
    "print(\"  ‚Ä¢ Forecasts assume historical trends continue\")\n",
    "print(\"  ‚Ä¢ Policy changes or interventions may alter trajectory\")\n",
    "print(\"  ‚Ä¢ Cloud masking provides more accurate baseline\")\n",
    "print(\"  ‚Ä¢ Monitor actual vs. predicted for model validation\")\n",
    "print(f\"  ‚Ä¢ Best performing model: {best_model} (RMSE: {best_rmse:.3f} km¬≤)\")\n",
    "\n",
    "print(\"\\nüí° Next Steps:\")\n",
    "print(\"  1. Validate predictions with field observations\")\n",
    "print(\"  2. Implement monitoring for high-risk zones\")\n",
    "print(\"  3. Develop intervention strategies for priority areas\")\n",
    "print(\"  4. Update model quarterly with new satellite data\")\n",
    "print(\"  5. Integrate with spatial risk analysis for targeted action\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ DEFORESTATION PREDICTION MODELING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
